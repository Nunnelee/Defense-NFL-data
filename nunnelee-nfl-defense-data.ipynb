{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NFL Defense Data Nunnelee Notebook\n\nThis competition uses NFL’s Next Gen Stats data, which includes the position and speed of every player on the field during each play. We'll employ player tracking data for all drop-back pass plays from the 2018 regular season. The goal of submissions is to identify unique and impactful approaches to measure defensive performance on these plays. There are several different directions for participants to utilize —which may require levels of football savvy, data aptitude, and creativity. As examples:\n\n* What are coverage schemes (man, zone, etc) that the defense employs? What coverage options tend to be better performing?\n* Which players are the best at closely tracking receivers as they try to get open?\n* Which players are the best at closing on receivers when the ball is in the air?\n* Which players are the best at defending pass plays when the ball arrives?\n* Is there any way to use player tracking data to predict whether or not certain penalties – for example, defensive pass interference – will be called?\n* Who are the NFL’s best players against the pass?\n* How does a defense react to certain types of offensive plays?\n* Is there anything about a player – for example, their height, weight, experience, speed, or position – that can be used to predict their performance on defense?\n* What does data tell us about defending the pass play?\n\n# Evaulation\nThe challenge is to generate actionable, practical, and novel insights from player tracking data that corresponds to defensive backs. Suggestions made here represent some of the approaches that football coaches are currently thinking of, but there undoubtedly several others.\n\nAn entry to the competition consists of a Notebook submission that is evaluated on the following five components, where 0 is the low score and 10 is the high score.\n\nNote: All notebooks submitted must be made public on or before the submission deadline to be eligible.\n\nOpen Competition: The first aim takes on what an NFL defense does once a quarterback drops back to pass. This includes coverage schemes (typically man versus zone), how players (often termed “secondary” defenders) disrupt and prevent the offense from completing passes, and how, once the ball is in the air, the defense works to ensure that a pass falls incomplete.\n\n## Big Data Bowl 2021 scoring sheet\nSubmissions will be judged by the NFL based on how well they address:\n\nInnovation:\n\nAre the proposed findings actionable?\nIs this a way of looking at tracking data that is novel?\nIs this project creative?\nAccuracy:\n\nIs the work correct?\nAre claims backed up by data?\nAre the statistical models appropriate given the data?\nRelevance:\n\nWould NFL teams (or the league office) be able to use these results on a week-to-week basis?\nDoes the analysis account for variables that make football data complex?\nClarity:\n\nEvaluate the writing with respect to how clear the writer(s) make findings.\nData visualization/tables:\n\nAre the charts and tables provided accessible, interesting, visually appealing, and accurate?\n\nNotebooks should consist of no more than 2,000 words and no more than 7 tables/figures. Submissions will not be penalized for any number of words or figures under this limit. Participants are encouraged to show statistical code if it helps readers better understand their analyses; most, if not all code, however, should be hidden in the Appendix."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing the tools\nWe're going to use Matplotlib, as well as Numpy and Pandas"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import all the tools we need\n\n# Regular EDA (exploratory data analysis) and plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# we want our plots to appear inside the notebook\n%matplotlib inline \n\n# Models from Scikit-Learn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Model Evaluations\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import plot_roc_curve","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the data\nThere is a lot of data bases. Player information, plays, games and plays for weeks 1 - 17. \n\nLet's start by consolidating weeks 1-16. This will create a large database, but create more relevance. Week 17 will be our test data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wk1 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week1.csv\")\n#df_wk2 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week2.csv\")\n#df_wk3 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week3.csv\")\n#df_wk4 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week4.csv\")\n#df_wk5 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week5.csv\")\n#df_wk6 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week6.csv\")\n#df_wk7 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week7.csv\")\n#df_wk8 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week8.csv\")\n#df_wk9 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week9.csv\")\n#df_wk10 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week10.csv\")\n#df_wk11 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week11.csv\")\n#df_wk12 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week12.csv\")\n#df_wk13 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week13.csv\")\n#df_wk14 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week14.csv\")\n#df_wk15 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week15.csv\")\n#df_wk16 = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week16.csv\")\n#df_test = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/week17.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's add the databases together\n#df_wks = df_wk1 + df_wk2 + df_wk3 + df_wk4 + df_wk5 + df_wk6 + df_wk7 + df_wk8 + df_wk9 + df_wk10 + df_wk11 + df_wk12 + df_wk13 + df_wk14 + df_wk15 + df_wk16\n#df_wks.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wk1.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's see what the other data holds"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_games = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/games.csv\")\ndf_games.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_games.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_players = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/players.csv\")\ndf_players.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_players.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plays = pd.read_csv(\"/kaggle/input/nfl-big-data-bowl-2021/plays.csv\")\ndf_plays.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plays.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis\nThe results per play is in the Plays data.\n\nLet's break down the play results first. Succesful Completion (C) and Defensive Penalties (DPI, DH, ICT) = Positive for offense. All other results are positives for defense."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plays.tail().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question: What is relevant? Narrow the focus.\n### First, let's identify the relevant info:\n* playResult: Was the offense succesful in completing a pass without an offensive penalty?\n* passResult: Outcome of the passing play (C: Complete pass, I: Incomplete pass, S: Quarterback sack, IN: Intercepted pass, text)\n* And what worked for the defense?\n\n### Second, let's assume this is the only relevant info in determining the results for our questions.\n* down\n* yardsToGo\n* personnelIO\n* personnelID\n* defendersInTheBox\n* penalties? Maybe, maybe not.\n\n### Third, let's see if we can seperate the passResult Completions from all other passResults, and create a database with only the relevant information."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets look at our current database\ndf_plays.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's drop the assumed irrelevant info\ndf_plays_rel = df_plays.drop([\"gameId\", \"playId\", \"playDescription\", \"quarter\",\"possessionTeam\", \"playType\",\n                             \"yardlineSide\",\"yardlineNumber\", \"offenseFormation\", \"numberOfPassRushers\",\n                             \"typeDropback\", \"preSnapVisitorScore\", \"preSnapHomeScore\", \"gameClock\", \n                             \"absoluteYardlineNumber\",\"penaltyCodes\", \"penaltyJerseyNumbers\",\"offensePlayResult\",\n                             \"epa\", \"isDefensivePI\"], axis=1)\ndf_plays_rel.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I need to seperate Completed passResults from the rest.\nHow do I do that?"},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_completed = df_plays_rel[df_plays_rel[\"passResult\"] == \"C\"]\npass_result_completed.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_completed.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cool. Let's look at the positive defensive data"},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_defense = df_plays_rel[df_plays_rel[\"passResult\"] != \"C\"]\npass_result_defense.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_defense.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Change our data into machine language. Yeah, that's right. Numbers!!!\nWe'll manipulate the offense first.\n\nThen we'll negotiate the defense. Football jargon.\n\nFirst, we'll elimnate the playResult, because we're only concerned if the pass was completed."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the playResult\npass_result_comp = pass_result_completed.drop(\"playResult\", axis=1)\npass_result_comp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now for the defense data\npass_result_def = pass_result_defense.drop(\"playResult\", axis=1)\npass_result_def.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Change the data\n\nConvert string into categories¶\n\nOne way we can turn all of our data into numbers is by converting them into pandas categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the columns which contain strings\nfor label, content in pass_result_comp.items():\n    if pd.api.types.is_string_dtype(content):\n        pass_result_comp[label] = content.astype(\"category\").cat.as_ordered()\n        \nfor label, content in pass_result_def.items():\n    if pd.api.types.is_string_dtype(content):\n        pass_result_def[label] = content.astype(\"category\").cat.as_ordered()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_comp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_def.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the missing data\npass_result_comp.isnull().sum()/len(pass_result_comp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_comp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fill the missing value first\nFill numerical values first"},{"metadata":{"trusted":true},"cell_type":"code","source":"# defendersInTheBox is missing 20 data points\n# Let's fill the numeric rows with the median\nfor label, content in pass_result_comp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            pass_result_comp[label] = content.fillna(content.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check if defendersInTheBox is filled\npass_result_comp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fill and turn the categorical variables (personnel Io and personnel Id) into numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for columns which are't numeric and turn categories into numbers and add +1\nfor label, content in pass_result_comp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        pass_result_comp[label] = pd.Categorical(content).codes+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_comp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_comp.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_comp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Convert our offense results into machine language, and do the same with the defense."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the missing data\npass_result_def.isnull().sum()/len(pass_result_def)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_def.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's fill the numeric rows with the median\nfor label, content in pass_result_def.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            pass_result_def[label] = content.fillna(content.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_def.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for columns which aren't numeric and turn categories into numbers and add +1\nfor label, content in pass_result_def.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        pass_result_def[label] = pd.Categorical(content).codes+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_def.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_def.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_result_def.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split our data into X & Y. Start with the defense"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pass_result_def.drop(\"passResult\", axis=1)\n\ny = pass_result_def[\"passResult\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's split the data into training and test sets\nnp.random.seed(7)\n\n# Split into train and test set\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                   y,\n                                                   test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, len(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train, len(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling\nNow we've got our data into training and test sets, it's time to build the model.\n\nWe'll train it (find the patterns) on the training set.\n\nAnd we'll test it (use the patterns) on the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n\nclf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=500)\nclf.fit(X,y)\n\nclf.score(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's look at XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb_model = XGBClassifier()\nxgb_model.fit(X,y)\n\nxgb_model.score(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance\n\nWhich attributes of the data were most important when it comes to predicting the target variable(passResult)."},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper function for plotting feature importance\ndef plot_features(columns, importances, n=10):\n    pass_result_def = (pd.DataFrame({\"features\": columns,\n                                     \"feature_importances\": importances})\n                       .sort_values(\"feature_importances\", ascending =False)\n                       .reset_index(drop=True))\n    # Plot the dataframe\n    fig, ax =plt.subplots()\n    ax.barh(pass_result_def[\"features\"][:n], pass_result_def[\"feature_importances\"][:10])\n    ax.set_ylabel(\"Features\")\n    ax.set_xlabel(\"Feature importance\")\n    ax.invert_yaxis()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_features(X_train.columns, xgb_model.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## As I thought, isDefensivePI is skewing the results. Let's go back up top, eliminate the category and look again.\nWent back and updated the data.\n\nAccording the feature importance, down and distance has the biggest impact on passResults. This make sense assuming that 3rd and long situations are hard to convert. Nothing revelatory here.\n\n## Need more EDA\nLet's look at our original data and re-focus what we are trying to find our with this data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wk1.head(10).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_games.head(10).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_players.head(10).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_plays.head(10).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recalculate positive and negative plays with regards to plays.\nNot ready to utilize the rest of the data just yet.\n\n### Positive plays would be if the defense prevented a first down or touchdown. playResult is less than yardsToGo.\n\n### Negative plays would be if the offense playResult was more than the yardsToGo.\n\n### Let's seperate the plays into different databases, and get rid of irrelevant data to these criteria.\n\n## Trying to create a Classification problem of whether or not the defense is successful in stopping the offense. And, how did they do it with the data provided. What are the most important features of the data that determined this, and can coaches use this information to make better defensive calls to improve the defense odds of success with similar situations? I.e. 3rd and 8 in the 4th quarter with 90 yards to score.\n\nIrrelevant criteria and why:\n* gameId: Looking for commonalities. Specific games and personnel are hard to quantify with the limited data available.\n* playId: Because it's not unique across games (numeric), hard to quantify with the limited data available.\n* playDescription: Looking for commonalities. Specific plays and personnel are hard to quantify with the limited data available and what we are trying to achieve. Also we're looking for future use, not if a player was a HOFer two years ago.\n* possessionTeam: Too specific.\n* playType: All of the plays are passes.\n* yardlineSide: Relevance? Can't see it for these purposes.\n* gameClock: May be relevant, hard to quantify relevance without more information.\n* penaltyJerseyNumbers: May only matter if a specific player always gets penalized.\n* epa: Expected points added skews results"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"# First the data reduction\ndf2_plays = df_plays.drop([\"gameId\", \"playId\", \"playDescription\", \"possessionTeam\", \"playType\", \"yardlineSide\", \"gameClock\", \"penaltyJerseyNumbers\", \"epa\"], axis=1)\n\ndf2_plays.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create a target (y) category that determines our definition of success.\n## Here's a reminder of our definition:\n### Positive plays would be if the defense prevented a first down or touchdown. playResult is less than yardsToGo. (1, or True)\n### Negative plays would be if the offense playResult was more than the yardsToGo. (0, or False)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the target column\ndf2_plays[\"Stopped\"] = df2_plays[\"playResult\"] < df2_plays[\"yardsToGo\"]\ndf2_plays.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Change Data into Machine Language\nConvert string into categories¶\n\nOne way we can turn all of our data into numbers is by converting them into pandas categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"for label, content in df2_plays.items():\n    if pd.api.types.is_string_dtype(content):\n        df2_plays[label] = content.astype(\"category\").cat.as_ordered()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_plays.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the missing data\ndf2_plays.isnull().sum()/len(df2_plays)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_plays.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's remove the penalty codes. Missing 18033.\ndf3_plays = df2_plays.drop([\"penaltyCodes\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3_plays.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill missing values with median\nfor label, content in df3_plays.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            df3_plays[label] = content.fillna(content.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3_plays.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn categorical values into numbers and fill missing\nfor label, content in df3_plays.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        df3_plays[label] = pd.Categorical(content).codes+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3_plays.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split our data into X & y\nX = df3_plays.drop(\"Stopped\", axis=1)\n\ny = df3_plays[\"Stopped\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model to the training data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try Forest Regression\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Instantiate model\nrf_model = RandomForestRegressor(n_jobs=1,\n                                random_state=7)\n\n# Fit the model\nrf_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score the model\nrf_model.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the test set\nrf_model.fit(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation function"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n\ndef rmsle(y_test, y_preds):\n    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n\ndef show_scores(rf_model):\n    train_preds = rf_model.predict(X_train)\n    test_preds = rf_model.predict(X_test)\n    scores = {\"Training MAE\": mean_absolute_error(y_train, train_preds),\n             \"Test MAE\": mean_absolute_error(y_test, test_preds),\n             \"Training RMSLE\": rmsle(y_train, train_preds),\n             \"Test RMSLE\": rmsle(y_test, test_preds),\n             \"Training R^2\": r2_score(y_train, train_preds),\n             \"Test R^2\": r2_score(y_test, test_preds)}\n    return scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_scores(rf_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HyperTune RandomizedSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nrf_grid ={\"n_estimators\": np.arange(5,50,10),\n         \"max_depth\": [None, 3,5,10],\n         \"min_samples_split\": np.arange(2,20,2),\n         \"min_samples_leaf\": np.arange(1,20,2),\n         \"max_features\": [0.5,1, \"sqrt\", \"auto\"],\n         \"max_samples\": [1000]}\n\nrs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs=1,\n                                                   random_state=7),\n                             param_distributions=rf_grid,\n                             n_iter=50,\n                             cv=5,\n                             verbose=True)\n\nrs_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the best model hyperparameters\nrs_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate scores for Random Search CV model\nshow_scores(rs_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train a model with the best Hyperparameters\n* Note: These were found after 50 iterations."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# Most ideal hyperparameters\nideal_model = RandomForestRegressor(n_estimators= 35,\n                                    min_samples_split= 10,\n                                    min_samples_leaf= 3,\n                                    max_samples= 1000,\n                                    max_features= 'auto',\n                                    max_depth= None,\n                                    random_state=7)\n\n# Fit the ideal model\nideal_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scores for the ideal_model\nshow_scores(ideal_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ideal_model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ideal model Feature Importances"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_featuresV2(columns, importances, n=20):\n    df3_plays = (pd.DataFrame({\"features\": columns,\n                               \"feature_importances\": importances})\n                 .sort_values(\"feature_importances\", ascending=False)\n                 .reset_index(drop=True))\n    \n    # Plot the dataframe\n    fig, ax = plt.subplots()\n    ax.barh(df3_plays[\"features\"][:n], df3_plays[\"feature_importances\"][:20])\n    ax.set_ylabel(\"Features\")\n    ax.set_xlabel(\"Feature Importance\")\n    ax.invert_yaxis()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_featuresV2(X_train.columns, ideal_model.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}